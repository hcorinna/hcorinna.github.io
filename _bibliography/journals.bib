---
---

@string{ACM = {Association for Computing Machinery,}}

@article{wehrli2021bias,
  abbr={Springer},
  title={Bias, awareness, and ignorance in deep-learning-based face recognition},
  author={Wehrli, Samuel and Hertweck, Corinna and Amirian, Mohammadreza and Gl{\"u}ge, Stefan and Stadelmann, Thilo},
  abstract={Face Recognition (FR) is increasingly influencing our lives: we use it to unlock our phones; police uses it to identify suspects. Two main concerns are associated with this increase in facial recognition: (1) the fact that these systems are typically less accurate for marginalized groups, which can be described as “bias”, and (2) the increased surveillance through these systems. Our paper is concerned with the first issue. Specifically, we explore an intuitive technique for reducing this bias, namely “blinding” models to sensitive features, such as gender or race, and show why this cannot be equated with reducing bias. Even when not designed for this task, facial recognition models can deduce sensitive features, such as gender or race, from pictures of faces—simply because they are trained to determine the “similarity” of pictures. This means that people with similar skin tones, similar hair length, etc. will be seen as similar by facial recognition models. When confronted with biased decision-making by humans, one approach taken in job application screening is to “blind” the human decision-makers to sensitive attributes such as gender and race by not showing pictures of the applicants. Based on a similar idea, one might think that if facial recognition models were less aware of these sensitive features, the difference in accuracy between groups would decrease. We evaluate this assumption—which has already penetrated into the scientific literature as a valid de-biasing method—by measuring how “aware” models are of sensitive features and correlating this with differences in accuracy. In particular, we blind pre-trained models to make them less aware of sensitive attributes. We find that awareness and accuracy do not positively correlate, i.e., that bias ≠ awareness. In fact, blinding barely affects accuracy in our experiments. The seemingly simple solution of decreasing bias in facial recognition rates by reducing awareness of sensitive features does thus not work in practice: trying to ignore sensitive attributes is not a viable concept for less biased FR.},
  journal={AI and Ethics},
  pages={1--14},
  year={2021},
  publisher={Springer},
  url = {https://doi.org/10.1007/s43681-021-00108-6},
  doi = {10.1007/s43681-021-00108-6},
}

@article{zaman2022methods,
  abbr={Frontiers},
  title={Methods for Uncovering Discourses That Shape the Urban Imaginary in Helsinki's Smart City},      
  author={Zaman, Sara and Hertweck, Corinna},
  abstract={In modern urban environments the technologies that are basic to everyday life have become further embedded in that life. Smart cities are one example of the acceleration of technological change in order to engage with urban sustainability challenges, with Artificial Intelligence (AI) tools as one mode of engagement. However, the discourses through which cities engage with smart city growth and management can have long-term consequences for diverse knowledge held within the imaginaries of situated smart urbanism. As the city of Helsinki increasingly focuses on sustainable smart city initiatives, concurrent research suggests that smart urbanism is at a crossroads, where developers must decide how smart cities choose to engage with its residents' knowledge. This research sets out to ask, how are top-down smart city interventions communicated on Twitter (de)legitimizing diverse knowledge in situated smart urbanism? We draw from Foucaudian theory to identify which discourses are elevated, through statements posted on the social media platform Twitter. By answering this question, our goal in this paper is to examine how Foucault's methods can be used to highlight unseen assumptions about smart urbanism in Helsinki. Our objective is to identify overarching narratives and potential contested conceptualizations of smart urbanism in Helsinki. With our methods, we contribute a novel angle to surfacing power relations that are becoming evident in the development of AI-governed smart cities.},
  journal={Frontiers in Sustainable Cities},
  volume={4},      
  year={2022},
  publisher={Frontiers},
  url={https://www.frontiersin.org/article/10.3389/frsc.2022.796469},       
  doi={10.3389/frsc.2022.796469},      
  code={https://github.com/hcorinna/smartHEL}
}

@article{hertweck2022designing,
  abbr={JLA},
  title={Designing Affirmative Action Policies under Uncertainty},
  author={Hertweck, Corinna and Castillo, Carlos and Mathioudakis, Michael},
  abstract={We study university admissions under a centralized system that uses grades and standardized test scores to match applicants to university programs. In the context of this system, we explore affirmative action policies that seek to increase the acceptance rate of underrepresented groups while still accepting students with high scores. Since there is uncertainty about the score distribution of the students who will apply to each program, it is unclear what policy would have the desired effect on the acceptance rates of different groups. We address this challenge by using a predictive model trained on historical data to help optimize the parameters of such policies. We find that a learned predictive model does significantly better than relying on the ideal parameters for the last year. At the same time, we also find that a large pool of historical data yields similar results as our predictive approach for our data. Due to the more complex nature of the predictive approach, we conclude that a simpler approach should be preferred if enough data is available (e.g., long-standing, traditional university programs), but not for newer programs and other cases in which our predictive strategy can prove helpful.},
  journal={Journal of Learning Analytics},
  doi={10.18608/jla.2022.7463},
  url={https://learning-analytics.info/index.php/JLA/article/view/7463},
  volume={9},
  number={2},
  pages={121--137},
  year={2022},
  publisher={Society for Learning Analytics Research},
  code={https://github.com/hcorinna/university-admissions}
}